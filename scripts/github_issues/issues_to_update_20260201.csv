"number","title","body","epic"
"11","Implement Snap to Hub Auto-Alignment","Create a command that automatically aligns the robot's heading and position to aim at the hub for scoring. This should use the Vision subsystem to detect the hub's position and create a PID control loop (using WPILib's PIDController) to rotate and/or adjust the robot's driving angle. Reference VisionIOLimelight for hub detection and use the drivetrain's applyRequest method to control movement. The command should finish when the robot is within angular tolerance (±3 degrees) of the hub and properly positioned for a shot. Test in simulation using Mechanism2d to visualize hub position and robot alignment, then validate on a full field with proper AprilTag positioning.","Automation"
"31","Implement FMS API Integration","Integrate with the FMS (Field Management System) API to track scoring events during matches. This includes reading alliance station data, match time, and game-specific information to enable context-aware autonomous and teleoperated behavior. Reference the WPILib DriverStation class for FMS communication.","Automation"
"117","Implement Turret Subsystem","Create a new turret subsystem following the AdvantageKit IO layer pattern (TurretIO interface, TurretIOSim for simulation, TurretIOWB for WoodBot hardware). The turret should rotate to aim at the hub/scoring target. Include methods for setting angle setpoints, reading encoder position, and controlling the motor. Add turret CAN ID to Constants.WoodBotConstants.","Subsystems"
"139","Update Motor Controller Spreadsheet for PracticeBot","Document all motor types (NEO, Falcon 500, etc.) and their associated motor controllers (SparkMax, TalonFX) for the practice bot hardware. Create or update a spreadsheet that maps each subsystem to its motors, CAN IDs, and controller types. This helps ensure correct hardware configuration when building practice bot IO implementations.","Subsystems"
"198","Add Sensor-Based Collection Detection to Middle Auto","Update the middle autonomous routine to use the indexer and intake sensors (defined in Constants.WoodBotConstants as INDEXER_SENSOR_PORT, INTAKE_SENSOR_PORT, etc.) to detect when game pieces are collected. The auto should wait for sensor confirmation before advancing to the next step. This prevents the robot from attempting to shoot without having a game piece.","Automation"
"103","Port CommandLogger utility from RainMaker25","Port the [CommandLogger utility class](https://github.com/FRCTeam360/RainMaker25/blob/main/src/main/java/frc/robot/utils/CommandLogger.java) from RainMaker25 to RainMaker26 for logging command start and end events.","Tooling"
"142","Implement Turret Subsystem Simulation","Create TurretIOSim class in the subsystems/Turret/ folder following the existing pattern from other subsystems (see FlywheelIOSim as example). Use DCMotorSim to simulate turret rotation physics. Include visualization using Mechanism2d to show turret angle on simulation dashboard. Test that turret can rotate to target angles and track hub position.","Simulations"
"101","Test Superstructure Subsystem in Sim","Once the Superstructure class is created (replacing CommandFactory), test it in simulation mode. Verify that the superstructure can coordinate multiple subsystems (intake, indexer, flywheel, hood, turret) together for complex actions like shooting. Check that state machines work correctly and subsystems don't interfere with each other. Use AdvantageScope to analyze logged data.","Simulations"
"14","Set Up Unit Testing for Subsystems","Set up a comprehensive unit testing framework for the robot codebase using JUnit (included with WPILib). Create test classes for critical subsystems and utility functions, focusing on mathematical calculations (shot calculator interpolations, odometry updates) and state machine logic. Place test files in src/test/java/frc/robot/ following the same package structure as main code. Start with at least 3-5 test cases per subsystem covering nominal behavior, edge cases, and error conditions. Use ./gradlew test to run tests. Acceptance criteria: All tests pass, code coverage > 70% for critical subsystems, tests execute in < 10 seconds. Document any testing setup instructions in the project README.","Tooling"
"37","Implement AprilTag Auto-Targeting","Implement a command that uses Vision subsystem data to aim the robot (and/or turret) at AprilTags on the field. Use the VisionMeasurement class and Limelight data (from VisionIOLimelight) to calculate the angle to the target. Create a simple PID controller to rotate the robot/turret to face the AprilTag. Reference WPILib's AprilTag documentation and the FIELD_LAYOUT constant.","Vision"
"46","Test Field Bump Impact on Localization","Validate the robot's localization accuracy (Vision + gyro fusion from the drivetrain subsystem) when traversing the field's center bump. Drive the robot over the bump at multiple speeds (low, medium, high) while logging pose data with AdvantageScope and gyro heading. Compare reported poses against known ground truth positions marked on the field. Measure: pose drift (max error vs ground truth after bump crossing), gyro heading error, and vision measurement latency/jumps during impact. Acceptance criteria: Pose error < 8cm after bump crossing at all speeds, gyro heading remains stable (< 5° deviation), no pose jumps > 15cm. Document any problematic scenarios and propose mitigation (e.g., pose resets when exiting bump zone).","Testing"
"70","Implement PathPlanner Steer Override for Autos","Add steer override functionality to PathPlanner autos using the SwerveRequest system. This allows the robot to automatically adjust its heading while following a path (e.g., to aim at a target while driving). Reference PathPlanner documentation on override feedback. Integrate with the drivetrain's applyRequest method. Test in simulation with FollowPathCommand.","Autos"
"71","Implement PID to Point for Climbing","Create a command that uses PID control to drive the robot to a specific field position (Pose2d) for climbing alignment. This should use the drivetrain's localization (from Vision and gyro) to calculate distance and angle to target. Use WPILib's PIDController or ProfiledPIDController for smooth motion. The command should finish when the robot is within tolerance of the target position.","Automation"
"72","Calibrate Limelight Cameras with Charuco Board","Perform camera calibration on 3 Limelights using the Charuco board calibration process. Follow the official Limelight documentation at https://docs.limelightvision.io/docs/docs-limelight/getting-started/performing-charuco-camera-calibration. Print the Charuco board pattern, position it in front of each Limelight, and capture calibration images through the Limelight web interface. Export calibration data and verify AprilTag detection accuracy improves. Test each calibrated Limelight by detecting AprilTags at various distances (0.5m to 8m) and verify reported poses are within ±2cm at close range and ±10cm at far range. Document calibration dates and AprilTag detection quality for each camera in the team wiki.","Vision"
"75","Research Steer Override for Autos","Research and document the PathPlanner steer override feature to enable dynamic heading control during autonomous path following. Study the PathPlanner documentation at https://pathplanner.dev/pplib-override-feedback.html and review how FRC 6328 implements override feedback in their 2026 code. Document: (1) How steer override modifies the drivetrain's heading setpoint in real-time, (2) integration points with the SwerveRequest system, (3) tuning parameters (override P gain, max angular velocity), and (4) practical use cases (aiming at target while driving, correcting for field drift). Create a technical summary document and prepare code examples showing how to add steer override to existing FollowPathCommand implementations. Prepare for implementation in issue #70.","Autos"
"104","Port RobotUtils Utility from RainMaker25","Port the RobotUtils utility class from RainMaker25 to RainMaker26 for USB writability checks.","Tooling"
"111","Refactor CommandFactory to Superstructure","Once Superstructure is tested and working, refactor RobotContainer to use Superstructure instead of CommandFactory. The Superstructure pattern coordinates subsystems better than CommandFactory by managing state and ensuring subsystems work together safely. Update all command bindings in configureBindings() to use superstructure methods. Remove CommandFactory.java after migration is complete.","Commands"
"121","Test and Tune Flywheel VelocityTorqueCurrentFOC","Test the flywheel subsystem using CTRE's VelocityTorqueCurrentFOC control mode on real hardware. Run the flywheel at various RPM setpoints and tune the PID constants (kP, kI, kD) in the motor configuration. Verify velocity control is accurate using Phoenix Tuner X. Log flywheel velocity and error to AdvantageKit. Optimal tuning ensures consistent shooting accuracy.","Testing"
"134","Implement Shoot-on-the-Move in Sim","Study and implement FRC 6328's shoot-on-the-move algorithm in simulation. This advanced feature allows the robot to shoot accurately while driving by calculating the required lead angle and flywheel velocity based on robot velocity and distance to target. Reference the ShotCalculator approach from Mechanical Advantage's 2026 code. Test thoroughly in sim before deploying to real hardware.","Automation"
"133","Create IntakePivot Stow/Deploy Command","Create a command that controls the IntakePivot subsystem to move between stowed and deployed positions. Use the IntakePivotIOSim implementation for testing. The command should set a target angle (e.g., 0° for stowed, 90° for deployed) and use the pivot's feedback control to reach the setpoint. Add IntakePivotVisualizer to show pivot angle in simulation GUI.","Simulations"
"154","Run SysID Characterization on Drivetrain","Execute SysID (System Identification) characterization on the swerve drivetrain using WPILib's SysID tool to measure motor dynamics. Run the characterization routines: quasistatic (slow ramp) and dynamic (fast pulse) tests for both linear and rotational motion. Use SysID Characterizer GUI to generate motor feedforward constants (kS, kV, kA) for the drivetrain motors. Collect data on real hardware in a controlled space (clear 30-foot straight line, level surface). Export the characterized values and update Constants.java with the new feedforward gains (likely in DrivetrainConstants). Verify improved trajectory tracking by running a path in simulation with new constants and comparing to actual robot performance. Acceptance criteria: Generated constants reduce steady-state tracking error by >20%, robot accelerates/decelerates smoothly, no jerky motion at low speeds.","Testing"
"157","Implement Controller Button Bindings for Teleop","Configure button bindings for both driver and operator controllers in RobotContainer's configureBindings() method. Map driver buttons to drivetrain-related commands (snap to hub, defense mode, path following overrides). Map operator buttons to subsystem commands: intake deploy/stow, indexer feed, shooter/flywheel speed control, turret aiming, and hood adjustment. Use WPILib's CommandXboxController for mapping (button(), leftTrigger(), etc.) and bind using onTrue(), onFalse(), or whileTrue() based on command lifecycle. Reference existing bindings in RobotContainer as a template. Include comments documenting which controller is responsible for each action. Acceptance criteria: All critical subsystems have assigned button controls, driver can operate drivetrain and vision-guided features, operator can control shooter pipeline independently. Test in simulation and on hardware to verify no button conflicts and responsive feedback.","Commands"
"158","Test Vision Localization Accuracy on Field","Validate the Vision subsystem's localization accuracy using real hardware on a full-size FRC field with properly positioned AprilTags. Place the robot at known positions (corners, center line, amp zone, wing, stage positions) and compare reported poses from the Vision subsystem against ground truth positions measured with a tape measure. Use AdvantageScope to log VisionMeasurement data and compare to estimated odometry-only poses. Test scenarios: (1) Stationary with multiple AprilTag views, (2) Driving straight at various speeds, (3) Rotating in place, (4) Dynamic conditions with partial tag occlusion. Measure accuracy metrics: average position error (< 5cm target), maximum position error (< 10cm), heading error (< 3 degrees). Log all data and identify any problematic zones or conditions. Document results and propose improvements if accuracy goals aren't met.","Vision"
"159","Implement Full Robot Simulation with All Subsystems","Ensure all robot subsystems are properly simulated and working together in WPILib's physics-based simulator. Each subsystem must have a working IOSim implementation (e.g., DrivetrainIOSim, FlywheelIOSim, IntakePivotIOSim). Verify DCMotorSim and LinearSystemSim physics models accurately represent hardware behavior. Add Mechanism2d visualizations for subsystems with moving parts (turret angle, hood angle, intake pivot). Register simulated commands in Autos.java for testing autonomous routines. Use ./gradlew simulateJava to run full simulation. Acceptance criteria: Full sim runs without errors, all subsystems respond to commands, Mechanism2d shows realistic motion (turret rotates, intake pivots, drivetrain moves), AdvantageScope can log all subsystem data in sim. Test at least one complete auto routine in simulation and verify coordination between drivetrain, shooter, and intake subsystems.","Simulations"
"161","Set Up IO Layers for PracticeBot","Set up IO layer implementations for the practice bot hardware using the AdvantageKit IO pattern. Review the practice bot's actual hardware configuration (motor types, CAN IDs, encoders, sensors) from the team's documentation or issue #139 (Motor Controller Spreadsheet). Create TurretIOPracticeBot, DrivetrainIOPracticeBot, and other subsystem-specific IO classes in subsystems/[SubsystemName]/ folders, mirroring WoodBot implementations (TurretIOWB, DrivetrainIOWB). Configure CAN IDs, motor inversions, and sensor ports to match practice bot hardware. Update Constants.java with PracticeBotConstants containing all practice bot-specific CAN IDs and configurations. Acceptance criteria: All subsystem IO classes compile without errors, CAN IDs and port assignments match actual hardware, code is ready to deploy to practice bot. Coordinate with #139 to ensure motor controller types and configurations are accurate.","Architecture"
"165","Create Automated Shooting Sequence Command","Create a comprehensive command that automates the complete shooting sequence: (1) snap robot heading to hub, (2) calculate required flywheel RPM and hood angle using ShotCalculator, (3) spin up flywheel to target RPM, (4) adjust hood to calculated angle, (5) aim turret at hub, (6) wait for all systems to reach setpoint (velocity within ±3% of target), (7) trigger indexer to feed game piece into shooter. Use the Superstructure pattern to coordinate subsystems (DeferredCommand pattern for sequencing). Include timeout to prevent infinite wait if hardware fails. Add state logging with AdvantageKit to track each sequence step. Acceptance criteria: Command completes autonomous shot in < 3 seconds from activation, flywheel achieves target velocity before shooting, game piece successfully exits robot. Test in simulation with visual feedback, then validate on practice bot and full field.","Commands"
"166","Create Passing Command to Alliance Partners","Create a command that enables the robot to pass (eject) game pieces to alliance robots at reduced power. Trigger the indexer and flywheel at lower RPM (e.g., 30% of shoot RPM) to launch the game piece toward a teammate rather than the hub. Accept an optional parameter for pass velocity or angle adjustment. Use the Superstructure pattern to coordinate indexer and flywheel subsystems. Include validation to ensure a game piece is in the indexer before passing (use sensor feedback from INDEXER_SENSOR_PORT). The command should complete when the piece exits the robot or after a timeout. Acceptance criteria: Game pieces can be successfully passed to another robot at 3-5 feet distance, command executes in < 2 seconds, pieces don't reach the hub when passing (reduced velocity). Test by manually placing game piece in indexer and running the command, verify trajectory and passing effectiveness.","Commands"
"167","Implement Shooting Mode Logic","Create decision logic that determines when the robot should attempt shooting vs. holding the game piece based on match state and robot position. Implement state transitions: (1) Idle (no piece), (2) Holding (piece in indexer), (3) Ready-to-Shoot (positioned and aimed at hub), (4) Shooting (executing shot), (5) Shot-Blocked (detected obstruction). Base decisions on: distance to hub (only shoot within optimal range, e.g., < 8m), match time remaining (adjust strategy near endgame), vision detection of hub/AprilTags (only shoot if hub is visible), and driver input (manual override). Implement as a state machine in Superstructure or dedicated ShootingLogic class using WPILib's state machine concepts. Log all state transitions with AdvantageKit for debugging. Acceptance criteria: Robot automatically chooses to shoot or hold based on field conditions, state transitions are smooth (no stuttering), driver can override at any time. Test in simulation with various field positions and match scenarios.","Automation"
"168","Implement Dynamic Target Selection Logic","Create a target selection system that dynamically chooses the optimal scoring target (hub, amp, etc.) based on robot position, remaining match time, and current match winner. Implement a state machine with targets: (1) Hub (default, high-scoring), (2) Amp (secondary, medium-scoring), (3) Pass (low-risk, support teammates). Selection logic: at start of teleop, score hub; at 30 seconds remaining, switch to amp if available; if robot is trailing, prioritize passing to enable teammate scoring; if already ahead, focus on personal scoring. Reference FIELD_LAYOUT and robot pose from Vision subsystem to calculate distances to each target. Update selected target in real-time as match state changes. Use Superstructure or dedicated TargetSelector class. Acceptance criteria: Target switches appropriately as match progresses, driver can see current target on dashboard, selected target affects shooting/passing command behavior. Test in simulation with various match scenarios (winning, losing, tied).","Automation"
"169","Implement Turret Auto-Tracking with Vision","Create a command that continuously tracks the hub with the turret subsystem using Vision data. The command should run throughout teleop, automatically rotating the turret to keep the hub centered in the Limelight's crosshair (or targeted region). Use VisionIOLimelight data to detect the hub's position (TX offset) and implement a PID controller (from WPILib) to drive the turret's setpoint angle toward the hub. The turret rotates via TurretIO subsystem calls. Handle cases where the hub is not visible by maintaining the last known angle or scanning. Include dashboard feedback showing current turret angle, hub position offset, and PID error. Acceptance criteria: Turret tracks visible hub with < 3° angular error, continues tracking while robot moves, smoothly handles hub occlusion. Test in simulation with hub visualization, then on field with proper AprilTag setup.","Automation"
"182","Add IntakePivot and Turret to Bulletproof Autos","Extend bulletproof autonomous routines to include simulated IntakePivot and Turret movements. Register named commands in Autos.java that control these subsystems (e.g., 'pivotDown', 'turretAimHub'). Test that autos correctly coordinate drivetrain, intake pivot, turret, and shooter subsystems together. Use PathPlanner's command markers to trigger subsystem actions at specific path points.","Simulations"
"185","Test Shoot-on-the-Move on Hardware","Test the shoot-on-the-move functionality on real hardware on a full field. Drive the robot at various speeds and angles while attempting to shoot into the hub. Verify that the ShotCalculator correctly compensates for robot velocity. Use AdvantageKit logging to analyze shot accuracy, flywheel RPM, hood angle, and turret angle. Tune parameters as needed for consistent scoring.","Testing"
"186","Implement Shoot to Arbitrary Point with Trajectory","Create a proof-of-concept command that shoots to an arbitrary field position (not just the hub). This requires calculating the trajectory based on target position, robot position, and distance. Implement trajectory math for projectile motion considering flywheel RPM and hood angle. Test in simulation first to validate calculations before trying on real hardware.","Simulations"
"189","Create ShotCalculator Class with Interpolation Maps","Create a shot calculator class with method calls for calculating flywheel rpm, hood angle, and turret angle based on robot position (relative to the hub) and velocity using interpolating tree maps like [6328 does](https://github.com/Mechanical-Advantage/RobotCode2026Public/blob/main/src/main/java/org/littletonrobotics/frc2026/subsystems/shooter/ShotCalculator.java)","Automation"
