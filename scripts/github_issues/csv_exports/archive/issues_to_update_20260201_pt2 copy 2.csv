number,title,body,milestone
176,Merge Vision Simulation Branch into Main,"Integrate the vision simulation branch into main to add Vision subsystem simulation capabilities with PhotonVision support. Start by checking out the vision simulation branch and inspecting the changes (use git diff main to compare). Before merging, resolve any merge conflicts with recent main branch updates, particularly in RobotContainer.java and any shared subsystem files. Run ./gradlew build to verify compilation succeeds, then ./gradlew test to ensure all unit tests pass. Check VS Code for any red squiggles or import errors related to PhotonSim libraries - these indicate classpath or dependency issues that need resolution in build.gradle or vendordeps/. Run a full simulation with ./gradlew simulateJava and verify the Vision subsystem initializes without errors in the console output. Open AdvantageScope and confirm Vision subsystem logging appears with fields like 'Vision/TargetVisible' and 'Vision/RobotPose'. Acceptance criteria: Branch merges cleanly with zero conflicts, gradle build completes without errors, simulation runs without crashes, Vision logging data appears in AdvantageScope at >5Hz update rate, and the Vision subsystem can detect simulated AprilTags in PhotonVision simulation. Test by running simulation, enabling Vision subsystem, and verifying tag detection in AdvantageScope logs.",Week 3
79,Create Vision-Based Target Alignment Commands,"Create vision-based alignment commands in CommandFactory.java that automatically rotate the robot to face detected AprilTags using the Vision subsystem data. Open CommandFactory.java and create two new command factory methods: alignToTargetRotateOnly() and alignToTargetDriveAndRotate(). Both commands should require the Drivetrain and Vision subsystems. In the command's execute() method, get the target bearing from vision.getInputs().targetYaw (the horizontal angle to the AprilTag). Calculate the angle error between the robot's current heading (from drivetrain.getRotation().getDegrees()) and the target bearing. Use drivetrain.applyRequest() with SwerveRequest.FieldCentricFacingAngle to smoothly rotate toward the target - set the target angle to the current heading plus the vision bearing offset. For the drive-and-rotate version, also set forward/strafe velocities to approach the tag. Add timeout logic using withTimeout(3.0) and end condition checking if Math.abs(angleError) < 3.0 degrees. Reference the Vision subsystem's @AutoLogOutput fields for accessing target data. Acceptance criteria: Robot rotates to face AprilTags within ±3° tolerance when tags are visible, commands timeout after 3 seconds if target is lost, rotation is smooth without oscillation, and both commands work in simulation and on real hardware. Test in simulation first by spawning AprilTags in different positions and verifying rotation, then test on practice field with properly mounted tags, monitoring alignment accuracy in AdvantageScope.",Week 3
196,Implement Drivetrain X-Formation Defensive Lock,"Create a defensive X-formation command that locks the swerve modules at 45° angles to prevent the robot from being pushed during defense or when disabled. The X-pattern (front-left: +45°, front-right: -45°, back-left: -45°, back-right: +45°) creates maximum resistance to lateral and rotational pushing. Open CommandFactory.java and add a new xOutCmd() method that returns a command. In the command, use drivetrain.applyRequest() with a SwerveRequest.SwerveDriveBrake request - this CTRE Phoenix 6 request type locks modules at specific angles. Set each module's angle using the SwerveModuleState constructor with zero velocity and the target angle as a Rotation2d. Reference the existing drive commands in CommandFactory for the applyRequest pattern. The command should run continuously (use Commands.run()) since it needs to maintain the X-formation until interrupted. Add constants XOUT_FL_ANGLE_DEG = 45.0, XOUT_FR_ANGLE_DEG = -45.0, etc. to Constants.WoodBotConstants if you want configurable angles. Acceptance criteria: All four swerve modules rotate to within ±2° of target angles, modules maintain position without drift for 10+ seconds, robot successfully resists pushing forces from multiple directions, and AdvantageScope shows module angles holding steady at target values. Test in simulation by running the command and checking 'Drivetrain/ModuleStates' logged angles, then test on WoodBot by running the command and attempting to push the robot from different directions while monitoring module angles in AdvantageScope.",Week 3
58,Implement Indexer Proximity Sensors for Game Piece Detection,"Add digital proximity sensors to the Indexer subsystem (which will be renamed to Hopper later) to detect when game pieces are present at different stages of the collection path. This enables automatic control - the robot knows when to stop intaking, when a piece is ready to shoot, etc. Start by adding sensor port constants to Constants.WoodBotConstants: add INDEXER_ENTRY_SENSOR_PORT (DIO port number, e.g., 0) and INDEXER_EXIT_SENSOR_PORT (e.g., 1) for sensors at intake entry and shooting exit positions. Open subsystems/Indexer/IndexerIOWB.java and create DigitalInput objects: 'private final DigitalInput entrySensor = new DigitalInput(Constants.WoodBotConstants.INDEXER_ENTRY_SENSOR_PORT);'. In the updateInputs() method, read sensor values with entrySensor.get() and store in the inputs object. Open IndexerInputsAutoLogged and add boolean fields: hasPieceAtEntry and hasPieceAtExit. Digital sensors typically return false when blocked (beam broken) and true when clear, so you may need to invert with !entrySensor.get() depending on sensor type. Add @AutoLogOutput annotations in Indexer.java for visibility. For simulation, create or update IndexerIOSim.java to simulate sensor behavior - start by having sensors always return false (no piece detected) until you implement game piece simulation later. Acceptance criteria: Sensor values update at >50Hz in AdvantageScope under 'Indexer/Inputs/', sensors correctly report true when beam is blocked and false when clear, readings are stable without rapid flickering between states, and you can manually trigger state changes by placing objects in sensor beams. Test on WoodBot by running the Indexer subsystem, monitoring sensor states in AdvantageScope, and manually placing/removing game pieces while verifying state changes occur correctly and reliably.",Week 3
137,Refactor Position Commands to Finish at Tolerance,"Refactor position-controlled commands to automatically complete when mechanisms reach their target positions, rather than running indefinitely until interrupted. This makes autonomous routines and command sequences more reliable since subsequent commands will only start after positioning finishes. Start with IntakePivot and Hood subsystems. First, add tolerance tracking to subsystem inputs: open IntakePivotInputsAutoLogged (generated class) and verify it has position-related fields, then add 'double setpointDegrees' and 'boolean atSetpoint' to the @AutoLog class. In IntakePivotIOWB.java's updateInputs() method, populate these fields: inputs.setpointDegrees = pivotMotor.getClosedLoopReference().getValueAsDouble(); and inputs.atSetpoint = Math.abs(inputs.setpointDegrees - inputs.positionDegrees) < Constants.WoodBotConstants.INTAKE_PIVOT_TOLERANCE_DEG;. Add the tolerance constant to Constants.WoodBotConstants (e.g., INTAKE_PIVOT_TOLERANCE_DEG = 2.0 for ±2° accuracy). Next, update CommandFactory.java commands: find the intakePivotSetPositionCmd() method and replace the current implementation (likely using runEnd()) with Commands.run(() -> intakePivot.setPosition(targetDegrees)).until(() -> intakePivot.getInputs().atSetpoint).withTimeout(3.0). The until() method makes the command finish when the condition is true, and withTimeout() ensures it doesn't hang forever if something goes wrong. Repeat this pattern for Hood, Turret, and any other position-controlled subsystems. Acceptance criteria: Commands finish automatically within 0.5 seconds of reaching target position, atSetpoint boolean correctly reflects mechanism state in AdvantageScope, commands timeout after 3 seconds if position is unreachable, no oscillation occurs within ±tolerance around setpoints, and autonomous routines progress smoothly through multi-step sequences. Test in simulation by commanding various positions to IntakePivot, monitoring 'IntakePivot/Inputs/atSetpoint' in AdvantageScope, and verifying commands complete promptly when position error drops below tolerance.",Week 3
52,Update TalonFX Constructors to Non-Deprecated API,"Update all TalonFX motor controller constructor calls to use the non-deprecated Phoenix 6 API that requires specifying the CAN bus name. CTRE deprecated the single-parameter constructor new TalonFX(canId) in favor of new TalonFX(canId, canBusName) to explicitly declare whether motors are on the RoboRIO's built-in CAN bus or a separate CANivore device. Use VS Code's search (Ctrl+Shift+F) to find all instances of 'new TalonFX(' - these will typically be in IO implementation files like DrivetrainIOWB.java, FlywheelIOWB.java, IntakePivotIOWB.java, HoodIOWB.java, etc. For each TalonFX constructor, add a second parameter: use ""rio"" if the motor is connected to the RoboRIO's CAN bus (most common), or ""canivore"" if your team uses a CANivore CAN bus extender (check with electrical team if unsure). For example, change 'private final TalonFX motor = new TalonFX(5);' to 'private final TalonFX motor = new TalonFX(5, ""rio"");'. If you're uncertain which bus a motor uses, check the electrical wiring diagram or ask the electrical team - using the wrong bus name will cause the motor to fail initialization. Make this change for every TalonFX in the codebase. Acceptance criteria: Zero deprecation warnings appear in build output when running ./gradlew build, all TalonFX motors show as 'connected' in Phoenix Tuner diagnostic page, no DriverStation errors about missing devices during robot startup, and all subsystems with TalonFX motors (Drivetrain, Flywheel, IntakePivot, Hood) operate normally in both simulation and on WoodBot. Test by building the project, reviewing the build output for warnings, deploying to WoodBot, and running through each subsystem's basic functions while monitoring for device errors in DriverStation.",Week 3
195,Port FieldConstants from FRC 6328 RobotCode2026,"Port FRC Team 6328's FieldConstants.java class into our codebase to provide standardized definitions of the 2026 game field geometry, including AprilTag positions, scoring zones, and key field landmarks. Navigate to https://github.com/Mechanical-Advantage/RobotCode2026Public/blob/main/src/main/java/org/littletonrobotics/frc2026/FieldConstants.java in your browser and copy the entire file content. Create a new file at src/main/java/frc/robot/FieldConstants.java in our project and paste the copied code. Update the package declaration at the top from 'package org.littletonrobotics.frc2026;' to 'package frc.robot;' to match our project structure. Add a credit comment at the top: '// Adapted from FRC 6328 RobotCode2026Public repository (https://github.com/Mechanical-Advantage/RobotCode2026Public)' followed by '// Modified for RainMaker26 Team 360'. Review the constant definitions - FieldConstants typically contains Translation2d and Pose2d objects representing AprilTag locations (as per FRC field layout), scoring positions, robot starting positions, and field boundaries. The coordinates are in meters with origin at the blue alliance corner. Verify that AprilTag positions match the official 2026 field layout from FIRST (check game manual Appendix for field drawings). You may need to update coordinates if 6328's version was from early season and doesn't match the final field specs. Acceptance criteria: FieldConstants.java compiles with zero errors, package declaration is correct, credit comment is present, all Translation2d/Pose2d constants use meter units, AprilTag positions match official 2026 field layout within ±5cm, and you can explain the purpose of at least 5 major constants. Test by creating a simple command that imports FieldConstants and prints an AprilTag position to console, then visualize the field layout by adding the constants to AdvantageScope's 2D field widget to verify positions match the field diagram visually.",Week 3
89,Set Up AprilTags on Practice Field,"Install physical AprilTag markers on the practice field at official 2026 game positions to enable vision-based robot localization testing. AprilTags are QR-code-like visual markers that the Limelight camera detects to determine the robot's position on the field. Start by downloading the official 2026 AprilTag images - visit the FRC Game Manual resources page or https://firstfrc.blob.core.windows.net/frc2026/FieldAssets/ to find the tag image files (usually PDF format). Print each tag at exactly 8.5 inches × 8.5 inches (verify with a ruler after printing - printer scaling can cause size errors). Mount each printed tag on rigid backing material like foam board or cardboard to keep them flat. Reference FieldConstants.java (from issue #195) or the official field CAD drawings to find each tag's position: X and Y coordinates on the field (in meters from blue alliance corner), Z height above floor (typically 1-2 meters), and rotation angle (tags face specific directions). Use a long tape measure and carpenter's level to mount tags accurately - position X/Y within ±2 inches (5cm) and rotation within ±5 degrees is acceptable for testing, but closer is better for accurate localization. Mount tags using camera tripods, PVC pipe stands, tape on walls, or temporary brackets - they must be sturdy enough not to move when bumped. Install all 16 tags from the 2026 field layout (IDs 1-16). Acceptance criteria: All 16 AprilTags are printed at correct 8.5""×8.5""size, mounted within ±2 inches of official positions, heights are within ±3 inches of specification, tags are rigidly mounted and don't wobble or shift, tag faces are perpendicular to their specified rotation angles within ±5°, and tags are visible from at least 10 feet away at typical robot camera height. Test by driving WoodBot around the practice field with the Vision subsystem active, verifying Limelight detects each tag from multiple positions/distances, checking that detected tag IDs in AdvantageScope match the tag numbers you mounted, and comparing Vision-reported robot poses against known measured positions on the field (error should be <20cm for well-positioned tags).",Week 4
51,Audit and Correct Motor Conversion Factors for Gear Ratios,"Audit and correct motor conversion factors across all subsystems to ensure gear ratios are properly accounted for when reading positions and velocities. A gear ratio is the mechanical reduction/multiplication between a motor shaft and the final output - for example, a 10:1 ratio means the motor spins 10 times for every 1 output rotation. Without proper conversion factors, a command to move 45° might actually move the mechanism 450° (if using raw motor rotations) or 4.5° (if ratio is backwards). Start by listing all subsystems with geared motors: IntakePivot, Hood, Turret, Flywheel, Intake, etc. For each subsystem, find the gear ratio from the CAD team or Constants.java (e.g., Constants.WoodBotConstants.INTAKE_PIVOT_GEAR_RATIO). Open the IO implementation file (e.g., IntakePivotIOWB.java) and locate the TalonFX configuration code (usually in the constructor). Phoenix 6 uses TalonFXConfiguration objects with Slot0Configs and FeedbackConfigs. In FeedbackConfigs, look for setRotorToSensorRatio() or setSensorToMechanismRatio() methods - these tell Phoenix how to convert motor rotations to mechanism units. For a pivot with a 50:1 gear ratio, motor makes 50 rotations per mechanism rotation, so use setSensorToMechanismRatio(1.0/50.0) to convert motor rotations to mechanism rotations. If you want degrees instead of rotations, multiply by 360: 360.0/50.0 = 7.2 degrees per motor rotation. Update the configuration, then verify in updateInputs() that the position and velocity are read correctly: inputs.positionDegrees = motor.getPosition().getValueAsDouble() should now return degrees, not rotations. Repeat for all geared subsystems, checking Hood, Turret, Intake, IntakePivot. Acceptance criteria: All position readings appear in AdvantageScope with correct units (degrees for angular mechanisms, meters for linear, RPM for wheels), commanding a mechanism to 90° results in the actual mechanism moving to 90° (measure with a protractor), velocity readings match hand-calculated expected values (e.g., motor at 6000 RPM with 10:1 ratio should show 600 RPM mechanism speed), and conversion factors match gear ratios from CAD within 5%. Test by commanding IntakePivot to 45°, 90°, and 180° in simulation, verifying positions in AdvantageScope match commanded values, then test on WoodBot by commanding positions and physically measuring mechanism angles with a protractor or digital angle finder.",Week 3
136,Port Auto-Encoder-Zeroing Command from RainMaker25,"Create an automatic encoder zeroing command that finds a mechanism's physical hard stop by detecting motor stall, then sets that position as the encoder zero point. This eliminates manual zeroing and ensures consistent starting positions. Reference the 2025 Laurens team code at https://github.com/FRCTeam360/RainMaker25 - look in their subsystems folder for an Elevator or similar mechanism with auto-zeroing logic. The zeroing process: (1) Command the mechanism to move slowly toward its hard stop using voltage control (e.g., -2.0 volts to move toward lower limit), (2) In each execute() cycle, read motor current (motor.getStatorCurrent().getValueAsDouble()) and velocity (motor.getVelocity().getValueAsDouble()), (3) Detect stall when current exceeds a threshold (e.g., >20 amps) AND velocity is near zero (e.g., <5 RPM) for a confirmation period (e.g., 0.25 seconds using a Timer), (4) Once stall is confirmed, stop the motor and call motor.setPosition(0.0) to set current position as zero, (5) Command the mechanism to move to a safe position away from the hard stop (e.g., +10 degrees). Implement this in CommandFactory.java as zeroIntakePivotCmd(), zeroHoodCmd(), etc. Add constants to Constants.WoodBotConstants: ZERO_VOLTAGE (e.g., -2.0), ZERO_STALL_CURRENT_AMPS (e.g., 20.0), ZERO_STALL_VELOCITY_RPM (e.g., 5.0), ZERO_CONFIRMATION_TIME_SEC (e.g., 0.25). Make the command require the target subsystem so it can't run while other commands are using it. Acceptance criteria: Command detects hard stop within 3 seconds of starting, mechanism stops within 0.5 seconds of stall detection, encoder position is set to zero point within ±0.5° accuracy, command doesn't damage mechanism or strip gears, subsequent position commands work correctly relative to the zeroed position, and zeroing works in both simulation (with simulated current limits) and on WoodBot. Test in simulation first by implementing current simulation in the IO sim class, then test on WoodBot with one team member ready at the driver station E-stop and another observing the mechanism to disable if anything goes wrong.",Week 3
110,Create Superstructure Migration Plan from CommandFactory,"Design a comprehensive migration plan to transition from our current CommandFactory pattern to a Superstructure-based architecture that coordinates multiple subsystems through a central state machine. Currently, commands are created independently in CommandFactory and composed manually - Superstructure will automatically coordinate complex multi-subsystem sequences like shooting (which needs intake, indexer, flywheel, hood, and turret working together in precise timing). Start by researching Superstructure implementations: review FRC Team 254's 2022-2023 code (https://github.com/Team254/FRC-2023-Public) and Team 6328's recent code for Superstructure examples - look for classes named Superstructure.java that contain state machines (enum-based state patterns or state machine libraries). Create a new document at docs/superstructure_transition_plan.md and structure it with these sections: (1) Current Architecture Overview - describe how CommandFactory and RobotContainer currently work, (2) Superstructure Architecture Overview - explain what Superstructure does and benefits (coordinated subsystem control, automatic state management, reduced command complexity), (3) Subsystem Coordination - list which subsystems need coordination (Intake, IntakePivot, Indexer, Flywheel, Hood, Turret, Vision) and which can stay independent (Drivetrain), (4) State Machine Design - define states like IDLE, INTAKING, INDEXING, SHOOTING, EJECTING with entry/exit conditions and subsystem actions per state, include a visual state diagram using Mermaid syntax, (5) Interface Design - show how RobotContainer will call Superstructure methods like setShooting(), setIntaking() instead of individual commands, (6) Migration Phases - outline 3-4 phases that add Superstructure incrementally without breaking existing code (Phase 1: Create empty Superstructure class and state enum, Phase 2: Migrate shooting sequence, Phase 3: Migrate intake sequence, Phase 4: Remove old CommandFactory methods), (7) Testing Strategy - define how to test each phase (simulation tests, hardware validation, comparison with old behavior), (8) Risks and Mitigation - identify potential issues like timing bugs or state machine deadlocks and how to prevent them. Acceptance criteria: Document is 3-5 pages covering all sections, state diagram includes 5+ states with clear transitions, migration plan has at least 3 phases that can be implemented incrementally, testing strategy defines specific test cases for each phase, risk section identifies 4+ potential issues with mitigation plans, and document has been reviewed and approved by 2+ programming team members. Share the document with the team for review and incorporate feedback before considering it complete.",Week 3
62,Collect Shooting Tuning Data for Distance Interpolation,"Gather empirical shooting data across multiple distances to build an interpolation lookup table that automatically adjusts hood angle and flywheel speed based on distance-to-target. This enables the robot to shoot accurately from anywhere on the field without manual tuning during matches. Set up the practice field with the scoring target in the correct position and mark distance lines using tape at 1.0m, 1.5m, 2.0m, 2.5m, 3.0m, 3.5m, 4.0m, 4.5m, and 5.0m from the target (use a long tape measure for accuracy). Position WoodBot at the first distance marker. Connect to the robot and open AdvantageScope or Phoenix Tuner. Start by setting a reasonable initial hood angle (e.g., 30°) and flywheel RPM (e.g., 3000) using manual controls or test commands. Shoot 3-5 game pieces and observe if they score - adjust hood angle and RPM incrementally until you achieve consistent successful shots. Once you find a good configuration, take 10 shots and record the number of successful scores. Open AdvantageScope and record the exact hood angle (read from 'Hood/Inputs/positionDegrees') and flywheel velocity (read from 'Flywheel/Inputs/velocityRPM') displayed during successful shots. Record this data in a spreadsheet (Google Sheets or Excel) with columns: Distance_Meters, Hood_Angle_Degrees, Flywheel_RPM, Successful_Shots, Total_Attempts, Success_Rate. Calculate Success_Rate = Successful_Shots / Total_Attempts. Repeat this process for all distance markers. Take more attempts (15-20) at critical distances like the typical shooting position used in matches. Save the spreadsheet as docs/shooting_data.csv in the repository. The collected data will later be used to implement an InterpolatingTreeMap (a data structure that interpolates between known points) in code - reference FRC 254's InterpolatingTreeMap implementation for how this works. Acceptance criteria: Data collected for at least 8 different distances between 1.0m and 5.0m, each distance has recorded hood angle and flywheel RPM values, each distance tested with at least 10 shot attempts, achieved configurations have >75% success rate, data shows logical trends (generally farther distances require higher RPM and/or different hood angles - graph the data to verify trends make sense), and data is saved in docs/shooting_data.csv with all required columns. Review the data with the team to identify any outliers or suspicious values before using it for interpolation implementation.",Week 4
85,Implement Robot Defense Mode Configuration,"Create a defense mode configuration that optimizes the robot for playing defense by increasing speed limits, stowing mechanisms, and enabling more aggressive driving characteristics. Defense mode is used when the strategy is to block opponents rather than score, requiring faster speeds and a more compact robot profile. Implement defense mode in RobotContainer.java with two approaches: (1) configuration management and (2) subsystem commands. For configuration, create a setDefenseMode(boolean enabled) method in RobotContainer that toggles between profiles. When enabled, update Drivetrain configuration: increase MAX_VELOCITY_METERS_PER_SECOND from normal 4.5 to 5.5 m/s, increase MAX_ANGULAR_VELOCITY from 8.0 to 12.0 rad/s for snappier turns, and increase acceleration limits for more responsive driving - add these alternate values as DEFENSE_MAX_VELOCITY_METERS_PER_SECOND etc. to Constants.WoodBotConstants. When defense mode activates, command all mechanisms to stow positions: run parallel command group that calls intakePivot.setPositionCmd(0), hood.setPositionCmd(0), etc. to retract everything into the frame perimeter - this minimizes the robot's profile for navigating tight spaces and reduces damage risk during contact. Add a NetworkTables boolean entry to control defense mode from the dashboard: use NetworkTableInstance.getDefault().getTable(""DriverControls"").getEntry(""DefenseMode"") and bind it to a button trigger in RobotContainer. Optionally, if LED subsystem exists, add visual indication by setting LED color to red during defense mode. Create a command wrapper defenseModeTeleopCmd() that combines the high-speed drive command with continuous mechanism stowing. Acceptance criteria: Defense mode increases max velocity by >1 m/s compared to normal mode, all mechanisms automatically stow to frame perimeter when defense mode enables, driver reports noticeably more aggressive/faster driving feel during testing, mode state is visible on driver dashboard with clear ON/OFF indication, robot can switch between normal and defense modes within 2 seconds, and configuration persists until manually disabled. Test in simulation by enabling defense mode and verifying higher velocity limits in AdvantageScope logs, then test on WoodBot by comparing driving feel and maximum speeds (measure time to drive 10 meters in each mode) with defense mode ON vs OFF.",Week 4
141,Fix REV Power Distribution Hub Logging in AdvantageKit,"Debug and fix Power Distribution Hub (PDH) data logging in AdvantageKit to properly capture voltage, current draw, and per-channel power consumption data. The PDH is the REV Robotics power distribution board that supplies power to all robot devices and monitors electrical usage - proper logging is critical for diagnosing electrical issues, detecting brownouts, and monitoring motor current draw. Start by locating where PDH is instantiated - search the codebase for 'PowerDistribution' (likely in Robot.java or RobotContainer.java). Verify the PDH is created with correct parameters: 'private final PowerDistribution pdh = new PowerDistribution(1, ModuleType.kRev);' where 1 is the CAN ID (check with electrical team for your PDH's actual ID, default is 1) and ModuleType.kRev specifies a REV PDH (not CTRE). Check if there's a PDH IO layer following the AdvantageKit pattern - look for PowerDistributionIO.java interface with PowerDistributionIOReal.java implementation. If not, you'll need to create one or use direct logging. In Robot.java's robotPeriodic() method, add logging for PDH values using Logger.recordOutput(): Logger.recordOutput(""PDH/Voltage"", pdh.getVoltage()), Logger.recordOutput(""PDH/TotalCurrent"", pdh.getTotalCurrent()), Logger.recordOutput(""PDH/TotalPower"", pdh.getTotalPower()). For individual channels, loop through important channels: for (int i = 0; i < 24; i++) { Logger.recordOutput(""PDH/Channel""+ i + ""Current"", pdh.getCurrent(i)); }. This logs all 24 PDH channels - you can reduce to only channels with devices connected for cleaner logs. Reference AdvantageKit's documentation on hardware logging patterns and check 6328's code for PDH logging examples. Acceptance criteria: PDH voltage appears in AdvantageScope under 'PDH/Voltage' and shows realistic values (11-13V typical), total current updates at >20Hz and increases when motors run, per-channel currents appear for all connected channels and show expected draw patterns (e.g., drivetrain motors draw 5-40A during movement, idle devices draw <1A), current readings are accurate within ±2A compared to REV Hardware Client measurements, and voltage drops during high current draw are visible in logs (helps diagnose brownout issues). Test by running the robot with AdvantageScope connected, enabling and running various subsystems (drivetrain, flywheel, intake), and verifying corresponding current spikes appear on the correct PDH channels in the AdvantageScope graphs.",Week 4
102,Port CommandLogger Utility from RainMaker25,"Port the CommandLogger utility from RainMaker25 to automatically log command lifecycle events (start, execute, end, interrupt) for debugging command scheduling and autonomous sequences. This utility hooks into WPILib's CommandScheduler to capture when commands begin and finish, making it much easier to diagnose why commands aren't running or why sequences behave unexpectedly. Navigate to https://github.com/FRCTeam360/RainMaker25/blob/main/src/main/java/frc/robot/utils/CommandLogger.java and copy the entire file content. Create the utils package if it doesn't exist: create src/main/java/frc/robot/utils/ directory. Create CommandLogger.java in that directory and paste the copied code. Update the package declaration from 'package frc.robot.utils;' to match (should already be correct). Review the CommandLogger implementation - it likely uses CommandScheduler.getInstance().onCommandInitialize(), onCommandExecute(), onCommandFinish(), and onCommandInterrupt() to register callbacks that fire when command lifecycle events occur. Update the logging mechanism to use AdvantageKit's Logger instead of System.out: replace any System.out.println() calls with Logger.recordOutput(""CommandLogger/Event"", message) where message includes the command name and event type. You may also want to log active command counts: Logger.recordOutput(""CommandLogger/ActiveCommands"", CommandScheduler.getInstance().getActiveCommands().size()). Open Robot.java and in the robotInit() method, initialize the logger early (before any commands are created): CommandLogger.getInstance().init(); - this ensures logging starts before the first command runs. Test in simulation to verify compatibility with WPILib 2026 API - the CommandScheduler callback methods may have changed between 2025 and 2026, so check WPILib documentation if you encounter errors. Acceptance criteria: CommandLogger.java compiles without errors, CommandLogger initializes in robotInit() without exceptions, command start events appear in AdvantageScope logs when commands begin (message format like '[Command] DriveCommand started'), command end events appear when commands finish/interrupt, log entries include command class name (not just object reference), command scheduler callbacks don't throw exceptions or crash the robot, and logging overhead is <1ms per event (measure with Logger performance metrics). Test by running simulation, executing several test commands from CommandFactory, and verifying their start/end events appear in AdvantageScope under CommandLogger outputs, then run a complex autonomous routine with 5+ sequential commands and verify all transitions are logged in order with correct timing.",Week 2
187,Integrate Onshape CAD Models for Simulation Visualization,"Import 3D CAD models from Onshape to enhance robot simulation visualization with realistic mechanism representations in AdvantageScope's 3D viewer, replacing simple shapes with actual CAD geometry. This is a lower-priority enhancement task that makes simulation more realistic and helps with design validation. Start by coordinating with the CAD/Design team - identify which mechanism models to import first (prioritize Drivetrain, IntakePivot, Hood as the most visually important). Have CAD team export these models from Onshape as STL or OBJ files (STL is preferred - binary format for smaller file size). WPILib and AdvantageScope support STL files directly but may need processing for large models. Create a new assets directory in the project: src/main/deploy/models/ and copy the exported STL files there. Models in deploy/ are automatically bundled with the robot code. For visualization, you have two approaches: (1) Use AdvantageScope's built-in 3D model support by logging Mechanism3d objects, or (2) Create a custom visualization layer. For AdvantageScope approach, create mechanism3d representations in each subsystem and update them based on encoder positions - reference AdvantageScope documentation at https://docs.advantagescope.org for Mechanism3d examples. For subsystems like IntakePivot, create a Mechanism3d that loads the STL file and rotates based on inputs.positionDegrees. Log these using Logger.recordOutput(""Mechanism3d/IntakePivot"", mechanism3d). The CAD models will need origin points aligned correctly - work with CAD team to ensure pivot points in the STL match the physical mechanism rotation points. You may need to use transformation matrices to position models correctly. Reference FRC 6328's visualization implementations for examples of CAD model integration. Start with one mechanism as a proof-of-concept before scaling to others. Acceptance criteria: At least 3 subsystem CAD models (Drivetrain, IntakePivot, Hood) are imported as STL files in src/main/deploy/models/, visualization code loads and renders STL models without errors, models update positions in real-time during simulation (rotation/translation based on subsystem encoder values), 3D visualization appears correctly in AdvantageScope's 3D viewer when playing back logs, model origins/pivot points align correctly with physical mechanisms, and visualization doesn't cause performance degradation (maintain >50 FPS in simulation). Test by running simulation, moving mechanisms through their full range of motion, recording an AdvantageScope log, and opening the log in AdvantageScope's 3D viewer to verify models appear and move correctly. This is Week 6 priority - focus on core functionality first.",Week 6
188,Implement LEDs Subsystem for Robot State Indication,"Create an LED subsystem to control addressable RGB LED strips for real-time visual feedback to the drive team on robot state. Reference FRC Team 3663's LED subsystem at https://github.com/team3663/2026-Rebuilt/tree/led/src/main/java/frc/robot/subsystems/led for patterns and ideas. Create subsystems/LEDs/ folder with LEDsIO interface, LEDsIOWB.java (hardware), and LEDsIOSim.java (simulation) following the AdvantageKit IO layer pattern. Use WPILib's AddressableLED class to control the LED strip. Add LED port number and strip length to Constants.WoodBotConstants (e.g., LED_PORT = 9, LED_LENGTH = 60). Implement methods to set LED colors and patterns: setSolidColor(r, g, b), setBlink(r, g, b, frequency), setRainbow(), setOff(). Create state-based LED control that automatically updates based on robot state: red when disabled, green when enabled, blue when ready to shoot, yellow when has game piece, flashing red when low battery. Coordinate with manufacturing team on physical LED strip installation location, power supply (may need additional 5V supply), and mounting. Acceptance criteria: LEDs can display at least 5 different states with distinct colors/patterns, patterns update automatically based on robot state changes, LEDs are bright enough to be visible from typical drive team positions (6-10 feet away), simulation properly simulates LED state in logs. Add a credit comment: ""// LED patterns inspired by FRC 3663's 2026 LED subsystem"". Test LED patterns in code before hardware installation, then validate on practice bot once LEDs are mounted and powered.",Week 5
190,Profile Robot Code Performance with VisualVM,"Use VisualVM profiler to identify CPU, memory, and threading bottlenecks in the robot code for potential optimization. Download and install VisualVM from https://visualvm.github.io/. Run the robot in simulation (./gradlew simulateJava) and use VisualVM to connect to the JVM: open VisualVM, look for a Java process related to WPILib/robot simulation (likely shows as 'Main' or with the WPILibJ icon), and click to connect. While the simulation is running, select the Profiler tab and start profiling CPU and memory. Run typical robot operations: drive the robot around (teleop command), execute an autonomous routine, run a shooter sequence. Let the profiler collect data for 30-60 seconds. Analyze the results: (1) Look at CPU tab and identify methods consuming >5ms per loop cycle - the main robot loop runs at 20ms (50Hz), so methods >5ms are taking >25% of available time, (2) Look at memory allocations and identify hotspots creating excessive objects, (3) Review thread tab to check for thread blocking or excessive synchronization, (4) Look for frequent garbage collection pauses. Take screenshots showing CPU hotspots and memory allocation patterns. Create a summary report in docs/performance_profiling.md documenting findings: which methods are slow, estimated time spent, whether it's a concern. Note: This is diagnostic/educational - only recommend optimizations if clear problems are found (e.g., a logging method taking 10ms of 20ms loop time). Acceptance criteria: Successfully connect profiler to running robot code, capture CPU and memory profiling data during robot operation (teleop and auto), identify all methods consuming >5ms per cycle, document findings with screenshots and analysis. Common bottlenecks to watch for: synchronous logging, blocking I/O operations, inefficient loops creating new objects in periodic methods, excessive string concatenation.",Week 4
191,OPTIONAL Evaluate AdvantageKit Swerve Template Migration,"Research and evaluate whether migrating to AdvantageKit's official swerve template is worth the effort - this template enables full log replay functionality (replaying logged robot behavior in simulation for debugging). Access AdvantageKit's template at https://github.com/Mechanical-Advantage/AdvantageKit/tree/main/example_projects/advanced_swerve_drive. Compare it against our current CommandSwerveDrivetrain implementation by reviewing: (1) code structure differences, (2) IO layer patterns used, (3) features gained (log replay, replay-based debugging), (4) breaking changes required, (5) estimated effort to migrate. Log replay is powerful - it lets you replay a match log in simulation to see exactly what happened and test fixes, but requires strict AdvantageKit IO pattern adherence for ALL hardware (not just subsystems). Estimate effort: review both codebases for 2-3 hours, document findings. Create a decision document in docs/advantagekit_swerve_template_evaluation.md analyzing: (1) What would need to change (drivetrain command structure, request generation, simulation), (2) Estimated hours to migrate (roughly 8-20 hours depending on complexity), (3) Risks (breaking existing working code, time commitment near competition), (4) Benefits (log replay for debugging, cleaner code structure), (5) Team consensus (should we do it?). This is OPTIONAL and LOW PRIORITY - only pursue if team agrees the log replay debugging capability is worth the migration cost and we have time before competition. Acceptance criteria: Evaluation document is clear and thorough, includes honest effort estimate, lists specific pros/cons, and includes explicit team decision (go/no-go). If go: create separate implementation issue. If no-go: close issue with documented rationale.",Week 4
203,Tune Swerve Heading PID Controller,"Tune the heading (rotation) PID controller for smooth, accurate swerve drivetrain rotation without oscillation or overshoot. The heading controller maintains robot orientation during teleop or when rotating to specific angles. Open Constants.java and locate heading PID constants in DrivetrainConstants (look for HEADING_KP, HEADING_KI, HEADING_KD). Use LoggedTunableNumbers feature from AdvantageKit to tune these values in real-time on WoodBot without rebuilding code. LoggedTunableNumbers allow live tuning via a web interface - reference AdvantageKit documentation. Alternatively, use Phoenix Tuner X's tuning interface if your drivetrain uses CTRE motor controllers. Deploy code to WoodBot and run teleop mode. Test rotations by: (1) Command 90° and 180° rotations and measure rotation time and overshoot, (2) Drive forward while maintaining a heading using field-centric mode, (3) Perform snap rotations (rapid heading changes) to test responsiveness. Tune starting with kP: slowly increase until the robot responds quickly but starts oscillating, then reduce by 30-50%. Add kD to dampen oscillation and improve settling time. Only add kI if significant steady-state error remains after kP/kD tuning. Target: robot rotates to commanded heading within ±2°, settles within 0.5 seconds, no visible oscillation or overshoot, maintains heading during straight driving. Document final tuned values in Constants.WoodBotConstants with a comment noting tuning date and conditions. Acceptance criteria: All three rotation tests pass without oscillation, heading is maintained during driving, settling time is <0.5 seconds for typical rotations, and constants are documented. Test on practice field to validate performance in realistic conditions.",Week 4
193,Refactor Indexer Subsystem to Hopper,"Rename the Indexer subsystem to Hopper to better reflect its expanded scope - it will coordinate multiple components (indexer wheel, sensors, kicker, etc.) not just the indexer wheel itself. Use IntelliJ's refactoring tools: right-click on Indexer.java → Refactor → Rename and choose 'All references'. This automatically updates: (1) Class name Indexer → Hopper in Indexer.java, (2) IndexerIO → HopperIO interface, (3) IndexerIOWB → HopperIOWB, (4) IndexerIOSim → HopperIOSim, (5) All references in RobotContainer.java, CommandFactory.java, and any imports. Also rename the folder: subsystems/Indexer/ → subsystems/Hopper/. Update Constants.java by renaming IndexerConstants (if it exists) to HopperConstants. Update any Dashboard display names from 'Indexer' to 'Hopper'. After renaming, build the project: ./gradlew build. Review build output for any missed references (search for remaining 'indexer' or 'Indexer' strings case-insensitively using grep or IDE search). Look especially in comments and string literals. Acceptance criteria: Project builds without errors, zero references to 'Indexer' class remain (comments can mention the indexer wheel component), subsystem functions correctly in simulation showing 'Hopper' in logs, all file/folder names use 'Hopper', existing functionality is unaffected. Test by running simulation and verifying Hopper subsystem appears in AdvantageScope logs with the new name.",Week 4
194,Clean Up VisionIOLimelight Constructor Code,"Refactor VisionIOLimelight.java's constructor to improve readability by extracting long configuration blocks into focused helper methods. Open subsystems/Vision/VisionIOLimelight.java and review the constructor - it likely contains inline configuration of the Limelight, PoseEstimator, AprilTag layout, and pipeline setup all in one large block. Refactor by: (1) Extract Limelight hardware initialization into initializeCamera() method, (2) Extract pose estimator setup into setupPoseEstimator() method, (3) Extract pipeline configuration into configurePipelines() method, (4) Replace all hardcoded magic numbers (LED blink rates, pipeline indices, exposure values, etc.) with named constants in Constants.VisionConstants (e.g., LIMELIGHT_LED_BLINK_RATE, DEFAULT_PIPELINE_INDEX). The constructor should become <20 lines with clear method calls showing initialization order. Example: constructor becomes: `public VisionIOLimelight() { initializeCamera(); configurePipelines(); setupPoseEstimator(); }`. Each helper method should be <20 lines with single responsibility. Verify Vision subsystem still works identically before/after refactoring. Acceptance criteria: Constructor is clean and delegates clearly, all magic numbers are named constants, code follows single responsibility principle, Vision subsystem compiles and functions identically, readability is improved (new developers can understand initialization flow quickly). Test by running simulation and comparing Vision output in AdvantageScope before/after refactoring - should be identical.",Week 4
209,Update AprilTag Field Layout for 2026 Game,"Update the AprilTagFieldLayout in Constants.java to use the official 2026 game field configuration instead of any 2025 or placeholder layouts. Download the official 2026 AprilTag field layout file from FRC resources: check the WPILib documentation or official FRC website for 2026 game assets (usually a JSON file with tag positions and IDs). Create src/main/deploy/apriltags/ directory if it doesn't exist and place the JSON layout file there (e.g., 2026-field.json). Open Constants.java and locate the AprilTagFieldLayout initialization (likely in VisionConstants). Update it to load the 2026 file: `AprilTagFieldLayout.loadFromResource(""aplayout/2026-field.json"")` (the path depends on file location). Verify the layout contains the correct number of AprilTags for 2026 (typically 16 tags) and that tag positions match the official game manual field drawing. If the official 2026 layout isn't available yet, create a placeholder from the game manual CAD or field specification. Update any hardcoded tag ID assumptions in Vision.java or other code to match the 2026 layout (e.g., if code assumed tag 1 is at blue corner, verify that's still true). Acceptance criteria: AprilTagFieldLayout loads the 2026 configuration without errors, tag count matches game manual, tag positions are accurate to within a few centimeters, Vision subsystem initializes without errors, and tag visualization in simulation or AdvantageScope field widget shows correct positions. Test by enabling Vision subsystem, viewing the field layout, and verifying AprilTag positions match your mental model of the official field.",Week 4
210,Reorganize Constants.java for Better Readability,"Restructure Constants.java to improve scannability by grouping all constants for each subsystem together in a logical, hierarchical organization. Currently WoodBot and Simulation constants for the same subsystem may be scattered, making it hard to find values during debugging. Reorganize the file structure as follows: (1) Add a section comment before each subsystem group: `// ==================== DRIVETRAIN ====================`, (2) Group subsystem constants in nested classes or regions: DrivetrainConstants, IntakeConstants, IntakePivotConstants, HopperConstants, FlywheelConstants, FlywheelKickerConstants, HoodConstants, TurretConstants, VisionConstants, LEDsConstants, etc., (3) Within each subsystem section, organize by category: CAN IDs first, then port numbers, then PID values, then physical/mechanical constants (gear ratios, limits), then tuning values, (4) Order subsystems logically: Drivetrain first, then subsystems in intake-to-shooter flow: Intake, IntakePivot, Hopper, Flywheel, FlywheelKicker, Hood, Turret, then Vision, then LEDs, (5) Add blank lines between subsystem sections for visual separation. After reorganizing, build the project: ./gradlew build. Verify all functionality is unchanged - this is purely organizational. Acceptance criteria: Constants.java is well-organized with clear subsystem sections, related constants are grouped together, section comments guide readers, blank lines improve visual separation, and gradle build succeeds without any behavioral changes. Test by running simulation and comparing robot behavior before/after - should be identical.",Week 4
211,Centralize USB Drive Path Constants,"Refactor hardcoded USB drive path strings scattered across the codebase into centralized Constants.java for consistency and maintainability. Search the entire codebase for hardcoded paths: use grep search for `""/U""` or similar USB mount paths. Common locations: RobotUtils.java (USB write operations), Robot.java or logging setup (AdvantageKit USB log directory), any file output operations. Create a new section in Constants.java for I/O paths: `public static final class IOConstants { public static final String USB_ROOT_DIRECTORY = ""/U""; public static final String USB_LOGS_DIRECTORY = ""/U/logs""; public static final String USB_EXPORTS_DIRECTORY = ""/U/exports""; }`. Replace all instances of the hardcoded ""/U"" string with references to Constants.IOConstants.USB_ROOT_DIRECTORY. For path concatenation, use Java NIO Paths for proper cross-platform handling: `Paths.get(Constants.IOConstants.USB_ROOT_DIRECTORY, ""logs"", filename).toString()` instead of manual string concatenation. This approach ensures: if USB mount point changes, update only one constant; paths are platform-aware; and code is more maintainable. Acceptance criteria: Zero hardcoded USB paths remain in code (except the constant definition), all file I/O uses the centralized constants, paths are constructed using Paths.get() for proper handling, USB logging still works correctly. Test by deploying to WoodBot with a USB drive and verifying logs are written to the expected location.",Week 4
212,Replace Misleading Debug Log in CommandSwerveDrivetrain,"Update a non-descriptive debug log message in CommandSwerveDrivetrain.java to provide meaningful feedback about code execution. Search CommandSwerveDrivetrain.java for the line containing `.alongWith(new InstantCommand(() -> System.out.println(""running"")))` which prints only ""running"" - this is too generic to be useful for debugging. Replace the message with descriptive text that clearly indicates what's executing, such as: - ""Running field-oriented drive teleop"" if this is the main teleop drive command, - ""Starting autonomous mode"" if in autonomous initialization, - or other context-specific description. The message should tell someone reading console output what specific action the robot is performing. While fixing this, consider: (1) Is the debug print statement still necessary? If not, remove the entire .alongWith(InstantCommand) clause to reduce noise, (2) Should this use Logger.recordOutput() instead of System.out.println()? Logger integrates with AdvantageKit for better visibility in AdvantageScope. If you see multiple similar generic print statements, fix all of them. Acceptance criteria: Log message is descriptive and clearly states what action is happening, message appears in console at the appropriate time when the command runs, no other generic ""running"" messages remain in the codebase. This makes code more maintainable for future developers trying to understand program flow.",Week 4
215,Add Guard Condition to startSimThread in CommandSwerveDrivetrain,"Add a defensive guard condition to CommandSwerveDrivetrain.startSimThread() to ensure only one simulation thread is created, preventing resource leaks if the method is called multiple times. Open CommandSwerveDrivetrain.java and locate the startSimThread() method. Review how/where it's called - it may be invoked from multiple constructors or initialization paths. At the beginning of startSimThread(), add a guard check: `if (m_simNotifier != null) { return; }` (m_simNotifier is assumed to be the Notifier or thread object - adjust variable name if different). This pattern ensures the method is idempotent - safe to call multiple times without side effects. Without this guard, multiple calls could create multiple Notifier threads competing for execution, wasting CPU cycles and causing unpredictable timing. After adding the guard, search the codebase for all calls to startSimThread() to document how often it's called and from where. Test by: (1) Creating a test that calls startSimThread() three times and verify only one thread exists (check with logging or thread inspection), (2) Running normal simulation to confirm the guard doesn't break anything. Acceptance criteria: Guard condition prevents duplicate thread creation, simulation still runs correctly, no resource leaks occur when startSimThread() is accidentally called multiple times, code is defensive and follows best practices for thread initialization. This is a safety improvement that prevents potential resource issues.",Week 4
217,Optimize Map Iteration in Vision Subsystem,"Refactor Vision.java's iteration loops to use more efficient and idiomatic Java patterns for map iteration. Open Vision.java and find loops iterating over the ios map (likely in the updateInputs() or periodic method). Look for patterns like: `for (String key : ios.keySet()) { VisionIO io = ios.get(key); ... }` which perform two map operations per iteration (keySet lookup, then get lookup). Replace with the more efficient pattern: `for (Map.Entry<String, VisionIO> entry : ios.entrySet()) { VisionIO io = entry.getValue(); String key = entry.getKey(); ... }` which gets both key and value in a single operation. The entrySet() pattern is both more efficient (one lookup instead of two) and more idiomatic Java. Apply the same optimization to any other map iteration loops in Vision.java (e.g., for visionInputs or similar). This is a minor performance optimization - the gains are small (microseconds per loop) but it follows best practices. While making this change, add a comment explaining the pattern: `// Use entrySet() for efficient key-value iteration in one pass` to help future maintainers understand the optimization. Acceptance criteria: Both identified loops use entrySet() iteration pattern, code compiles and functions identically, Vision subsystem behavior unchanged in simulation, logs show same data as before refactoring. This is a good practice improvement with no functional change - helps with code quality and maintainability.",Week 4
218,Extract Simulation Tick Rate to Constants,"Centralize hardcoded simulation update rate values (0.02 seconds = 20ms) scattered across subsystem simulation classes into a single shared constant. Search the codebase for hardcoded 0.02 values in all IO simulation classes: use grep to find `.update(0.02)` or similar patterns in IntakePivotIOSim.java, FlywheelIOSim.java, HoodIOSim.java, TurretIOSim.java, and any other *IOSim classes. Create a new constant section in Constants.java: `public static final class SimulationConstants { public static final double SIM_TICK_RATE_S = 0.02; // 20ms, matches WPILib periodic loop rate }` (the _S suffix indicates the unit is seconds). Replace all hardcoded 0.02 values with Constants.SimulationConstants.SIM_TICK_RATE_S. This improves maintainability - if the simulation update rate ever needs to change (e.g., to 0.01 for higher fidelity), update only one value instead of searching the entire codebase. Note: 20ms matches WPILib's standard periodic loop rate, so this shouldn't normally change, but centralizing it is still good practice. Search carefully for all instances - they might appear as 0.02, 0.020, or in expressions like `1.0 / 50.0`. Acceptance criteria: All hardcoded 0.02 tick rates are replaced with the constant reference, simulation behavior is identical before/after refactoring (verify in AdvantageScope logs), gradle build succeeds. Test by running simulation and comparing subsystem behavior - all should update at the same rate as before, no behavioral changes.",Week 4
223,Research PathPlanner Dynamic Path Selection,"Research and document PathPlanner's capabilities for runtime path selection based on robot state during autonomous routines. This enables autos that adapt (e.g., skip intake if hopper is full). Review PathPlanner documentation at https://pathplanner.dev/home.html and search for: dynamic pathing, event markers, conditional commands, runtime path selection, path groups. Study code examples from FRC 6328 or other teams using PathPlanner dynamic features. Key questions to investigate: (1) Can we select between different paths based on a condition (if hopper.isFull() return shootPath else return intakeThenShootPath)?, (2) Do event markers support conditional logic or just sequential commands?, (3) Can we build auto routines programmatically using command groups to enable dynamic routing?, (4) Are there limitations or gotchas? Document findings in docs/pathplanner_dynamic_routing.md with sections: (1) Dynamic Path Selection Capabilities - what PathPlanner supports, (2) Code Examples - pseudocode or actual examples of conditional path selection, (3) Limitations - what's not possible, (4) Recommended Approach - specific implementation strategy for our middle auto scenario (collecting pieces conditionally). If PathPlanner doesn't support dynamic paths natively, investigate workarounds: conditional command groups, event marker conditions, or hybrid programmatic + pathname routing. Acceptance criteria: Research document is comprehensive and clearly explains dynamic path options, includes code examples or pseudocode, identifies limitations honestly, recommends a specific implementation approach suitable for our auto routines. If feasible approach is found, create a follow-up implementation issue (#225 or similar) to implement the dynamic routing feature.",Week 4
224,Implement Limelight Rewind for Critical Events,"Implement Limelight 4's Rewind feature to automatically capture detailed vision data during critical game actions (shooting, auto-alignment, scoring) for comprehensive post-match debugging. Limelight Rewind continuously buffers camera frames and vision data, allowing you to save the last N seconds when an event occurs - invaluable for diagnosing alignment failures, missed shots, or vision pipeline issues. Access the Limelight API documentation (https://docs.limelightvision.io/) and search for Rewind capture commands. Typically this involves sending a NetworkTables command to the Limelight or making an HTTP request to trigger a capture. Add a method to VisionIOLimelight: `public void captureRewind(String eventName)` that triggers a Rewind capture with a descriptive event name (e.g., ""shot_attempt"", ""auto_align_start"", ""scoring_attempt""). Call this method at critical points in the code: before executing AutomaticShootingSequenceCommand, when auto-alignment completes, when autonomous scoring starts, etc. Configure Limelight's web interface settings: Rewind buffer duration (recommend 5-10 seconds to capture context), storage location (USB drive), and enable Rewind feature. The captured files should be saved with timestamps and event names for easy identification (e.g., ""rewind_shot_attempt_2026-02-05_14-32-05.log""). Create at least 3 different event types that trigger captures: shot attempts, auto-alignment events, autonomous scoring. After matches, download the Rewind capture files from the Limelight for offline analysis using Limelight's Rewind viewer. Acceptance criteria: Rewind captures are automatically triggered during shooting and other critical events without manual intervention, capture files are saved with descriptive names including timestamps and event types, at least 3 different event types trigger captures, captured files contain 5+ seconds of video and vision data before the event, files are accessible for review after matches. Test by running autonomous or teleop scoring sequences and verifying Rewind files are created. This is a Week 5 priority - a debugging enhancement, not core functionality.",Week 5